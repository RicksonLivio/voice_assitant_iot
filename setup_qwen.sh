#!/bin/bash
# Setup Script for Voice Assistant with Qwen2.5:1.5B
# Qwen2.5 is a superior model with better reasoning and multilingual support

set -e  # Exit on error

echo "=========================================="
echo "  Voice Assistant Setup"
echo "  With Qwen2.5:1.5B (Superior Model)"
echo "=========================================="
echo ""

# Color codes
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if running in correct directory
if [ ! -f "pyproject.toml" ]; then
    echo -e "${RED}Error: pyproject.toml not found. Please run this script from the project root.${NC}"
    exit 1
fi

# Display model information
echo -e "${BLUE}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
echo -e "${BLUE}  QWEN2.5:1.5B MODEL INFORMATION${NC}"
echo -e "${BLUE}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
echo ""
echo -e "${GREEN}Why Qwen2.5 instead of TinyLlama?${NC}"
echo "  ‚úì Better reasoning and logic"
echo "  ‚úì Superior instruction following"
echo "  ‚úì Multilingual support (29 languages)"
echo "  ‚úì More coherent responses"
echo "  ‚úì Better context understanding"
echo ""
echo -e "${YELLOW}Trade-offs:${NC}"
echo "  ‚Ä¢ Slightly slower (~3-5s vs 2-3s)"
echo "  ‚Ä¢ Slightly more RAM (~2GB vs 1.5GB)"
echo "  ‚Ä¢ Larger download (~950MB vs 700MB)"
echo ""
echo -e "${GREEN}Worth it? Absolutely for better conversations!${NC}"
echo ""
read -p "Press ENTER to continue with Qwen2.5 setup..."
echo ""

# Step 1: Update system packages
echo -e "${GREEN}[1/10] Updating system packages...${NC}"
sudo apt update
sudo apt install -y build-essential python3-dev portaudio19-dev \
    libportaudio2 ffmpeg espeak espeak-data libespeak-dev git wget curl \
    libsndfile1 cmake

# Step 2: Create/activate virtual environment
echo -e "${GREEN}[2/10] Creating virtual environment with UV...${NC}"
if [ ! -d ".venv" ]; then
    uv venv
fi
source .venv/bin/activate

# Step 3: Install PyTorch (CPU version)
echo -e "${GREEN}[3/10] Installing PyTorch (CPU version)...${NC}"
uv pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu

# Step 4: Install Kokoro TTS (natural voice)
echo -e "${GREEN}[4/10] Installing Kokoro TTS (natural human-like voice)...${NC}"
if uv pip install kokoro-tts 2>/dev/null; then
    echo -e "${GREEN}‚úì Kokoro TTS installed successfully!${NC}"
else
    echo -e "${YELLOW}‚ö†Ô∏è  Kokoro TTS installation failed, will use pyttsx3 fallback${NC}"
fi

# Step 5: Install other dependencies
echo -e "${GREEN}[5/10] Installing other dependencies...${NC}"
uv pip install openai-whisper numpy scipy sounddevice soundfile pyaudio pyttsx3 llama-cpp-python pyyaml

# Step 6: Create models directory
echo -e "${GREEN}[6/10] Creating models directory...${NC}"
mkdir -p models

# Step 7: Download Whisper model
echo -e "${GREEN}[7/10] Pre-downloading Whisper model...${NC}"
python3 << 'PYEOF'
import whisper
print("Downloading Whisper 'tiny' model...")
model = whisper.load_model("tiny")
print("‚úì Whisper model downloaded successfully!")
PYEOF

# Step 8: Download Qwen2.5:1.5B model
echo -e "${GREEN}[8/10] Downloading Qwen2.5:1.5B model (~950MB)...${NC}"
echo -e "${BLUE}This is a high-quality model - the download is worth it!${NC}"
if [ ! -f "models/qwen2.5-1.5b-instruct-q4_k_m.gguf" ]; then
    cd models
    
    # Download from HuggingFace
    echo "Downloading from HuggingFace..."
    wget -q --show-progress https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf
    
    cd ..
    echo -e "${GREEN}‚úì Qwen2.5 model downloaded!${NC}"
else
    echo -e "${YELLOW}Model already exists, skipping download.${NC}"
fi

# Step 9: Copy Qwen config
echo -e "${GREEN}[9/10] Setting up Qwen2.5 configuration...${NC}"
if [ -f "config_qwen.yaml" ]; then
    cp config_qwen.yaml config.yaml
    echo -e "${GREEN}‚úì Configuration updated for Qwen2.5${NC}"
else
    echo -e "${YELLOW}‚ö†Ô∏è  config_qwen.yaml not found, keeping existing config${NC}"
fi

# Step 10: Test installation
echo -e "${GREEN}[10/10] Testing installation...${NC}"
python3 << 'PYEOF'
print("\nTesting imports and components...")
passed = []
failed = []

# Test PyTorch
try:
    import torch
    passed.append(f"‚úì PyTorch {torch.__version__}")
except ImportError as e:
    failed.append(f"‚úó PyTorch: {e}")

# Test Whisper
try:
    import whisper
    passed.append("‚úì Whisper (Speech Recognition)")
except ImportError as e:
    failed.append(f"‚úó Whisper: {e}")

# Test llama-cpp-python
try:
    from llama_cpp import Llama
    passed.append("‚úì llama-cpp-python (LLM Engine)")
except ImportError as e:
    failed.append(f"‚úó llama-cpp-python: {e}")

# Test Kokoro TTS
try:
    from kokoro import generate
    passed.append("‚úì Kokoro TTS (Natural Voice) - EXCELLENT!")
except ImportError:
    passed.append("‚ö†Ô∏è  Kokoro TTS not available (will use pyttsx3)")

# Test pyttsx3
try:
    import pyttsx3
    passed.append("‚úì pyttsx3 (TTS Fallback)")
except ImportError as e:
    failed.append(f"‚úó pyttsx3: {e}")

# Test sounddevice
try:
    import sounddevice
    passed.append("‚úì sounddevice (Audio Recording)")
except ImportError as e:
    failed.append(f"‚úó sounddevice: {e}")

# Test numpy
try:
    import numpy
    passed.append("‚úì NumPy (Audio Processing)")
except ImportError as e:
    failed.append(f"‚úó NumPy: {e}")

# Test scipy
try:
    import scipy
    passed.append("‚úì SciPy (Signal Processing)")
except ImportError as e:
    failed.append(f"‚úó SciPy: {e}")

# Test yaml
try:
    import yaml
    passed.append("‚úì PyYAML (Configuration)")
except ImportError as e:
    failed.append(f"‚úó PyYAML: {e}")

# Print results
print("\n" + "="*50)
for item in passed:
    print(item)

if failed:
    print("\n‚ö†Ô∏è  Some dependencies failed:")
    for item in failed:
        print(item)
else:
    print("\n‚úÖ All core dependencies installed successfully!")

# Check Qwen model
import os
if os.path.exists("models/qwen2.5-1.5b-instruct-q4_k_m.gguf"):
    print("\n‚úì Qwen2.5:1.5B model ready!")
    size_mb = os.path.getsize("models/qwen2.5-1.5b-instruct-q4_k_m.gguf") / (1024*1024)
    print(f"  Model size: {size_mb:.1f} MB")
else:
    print("\n‚úó Qwen2.5 model not found")
PYEOF

echo ""
echo -e "${GREEN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
echo -e "${GREEN}  Setup Complete!${NC}"
echo -e "${GREEN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
echo ""
echo -e "${BLUE}‚ú® QWEN2.5:1.5B FEATURES:${NC}"
echo "  ‚Ä¢ Superior reasoning and logic"
echo "  ‚Ä¢ Multilingual support (29 languages)"
echo "  ‚Ä¢ Better instruction following"
echo "  ‚Ä¢ More coherent conversations"
echo "  ‚Ä¢ Natural human-like voice (Kokoro TTS)"
echo "  ‚Ä¢ Smart voice detection"
echo "  ‚Ä¢ Noise-robust recording"
echo ""
echo -e "${GREEN}üöÄ NEXT STEPS:${NC}"
echo "  1. Activate the environment: source .venv/bin/activate"
echo "  2. Run the assistant: python3 voice_assistant.py"
echo "  or"
echo "  3. Use the launcher: ./start_assistant.sh"
echo ""
echo -e "${YELLOW}üí° CONFIGURATION:${NC}"
echo "  ‚Ä¢ Edit config.yaml to adjust settings"
echo "  ‚Ä¢ Model path: ./models/qwen2.5-1.5b-instruct-q4_k_m.gguf"
echo "  ‚Ä¢ Adjust energy_threshold for your environment"
echo ""
echo -e "${BLUE}üìä PERFORMANCE EXPECTATIONS:${NC}"
echo "  ‚Ä¢ Startup: 5-10 seconds"
echo "  ‚Ä¢ Response time: 3-5 seconds"
echo "  ‚Ä¢ Memory usage: ~2GB RAM"
echo "  ‚Ä¢ Quality: Excellent!"
echo ""